
\section{Some Exploitable Properties about SAT}
In this section we explain some concepts of SAT that are interesting on that they have beautiful related maths theories related and that can be useful resolving and analyzing complexity. Aslo, we will develop some result that where intentionally postponed, in order to talk about them once complexity classes has been introduced, although they belong thematically to previous chapters. In particular we will talk about:
\begin{itemize}
\item Symmetric Clauses. 
\item Autarks assignments.
\item Tseitin Theorem.
\item Tautologies and CO-NP completeness
\item Constructiveness.
\end{itemize}

The first of them are useful when modelling a problem in order to generate SAT problems on which we can work more efficiently. Then second of them is an useful technique that is used extensively on SAT solvers



\subsection{Symmetry}
\label{sub:Symmetry}
In this subsection we talk about symmetry groups and its application to SAT. The information and examples resemble the ones in \cite{sakallah2009symmetry}. We will start this subsection with a motivating example.


\begin{example}
Consider the boolean formula:

  $$F = (\neg a \land b  \land c) \lor (a \land \neg b \land c).$$

It is not difficult to see that this functions remains invariant under some variations, namely:

\begin{itemize}
\item The trivial variation: the identity. For the example, we will denote this transformation by  $I$.

\item Swapping the inputs of $a$ and $b$. It is equivalent to renaming $a$ as $b$ and $b$ as $a$. For the example, we will denote this transformation as $\pi$: 
\begin{equation}\label{3.1}
\pi(F)& = (\neg b \land a  \land c) \lor (b \land \neg a \land c)\\ & = (\neg a \land b  \land c) \lor (a \land \neg b \land c) = F.\\
\end{equation} 
\item  Swapping the inputs of $a$ and $\neg b$. It is equivalent to renaming $a$ as $\neg b$ and $b$ as $\neg a$. For the example, we will denote this transformation as $\beta$: 
\begin{equation} \label{3.2}
\begin{split}
  \beta(F)& = (\neg \neg b \land \neg a  \land c) \lor (\neg b \land \neg \neg a \land c)\\ & = (\neg a \land b  \land c) \lor (a \land \neg b \land c) = F.\\
\end{split}
\end{equation}

  
\item Swapping $a$ with $\neg a$ and $b$ with $\neg b$. For the example, we will denote this transformation as $\gamma$:

\end{itemize}
\begin{equation} \label{3.3}
\begin{split}
  \gamma(F)& = (\neg \neg a \land \neg b  \land c) \lor (\neg a \land \neg \neg b \land c)\\ & = (\neg a \land b  \land c) \lor (a \land \neg b \land c) = F.\\
\end{split}
\end{equation}


With these three invariants we can also see that the composition of each one of these invariants with each other produce another invariant. Moreover, each invariant is its own inverse, as $\varphi \circ \varphi = I $ for $\varphi \in \{I, \alpha, \beta, \gamma\}$.\\

We can see therefore that by invariant $\gamma$, it does not matter what value does we assign to $a$, as either both $F\{a = 1\}$ and $F\{a=0\}$ are satisfiable or none are. Therefore we can solve$F\{a=1\}$, and we have a simplified problem to examine.

\end{example}



This is what is called \emph{symmetry breaking}. An avid reader would have already recognized the group structure on the invariants.  On this subsection we are going to explore the concepts related to define a symmetry, explore the group of negations and permutations, and develop some strategies to implement \emph{symmetry breaking}.  Now we are going to define a few concepts.


\begin{definition}
Let $F$ be a formula and $\phi$ be a function $\alpha:Form_{Var(F)}\to Form_{Var(F)}$. We say that $\phi$ is an invariant of $F$ if $\phi(F) = F$.
\end{definition}

 We have a function $\alpha :Form_{X}\to Form_{X}$ that maps $F = (\neg a \land b  \land c) \lor (a \land \neg b \land c)$ to $\alpha(F) = (\neg c \land b  \land a) \lor (c \land \neg b \land a)$.\\



 \begin{definition}[Group Action]
  An \emph{action} of a group $G$ on a set $S$ is a map $G \times S \to S$ such that:
  \begin{itemize}
  \item $es = s$ for $e$ the identity element of $G$ and every $s\in S$.
  \item $(g_1g_2)(s) = g_1(g_2s)$ for all $s \in S$ and all $g_1,g_2\in G$.
    \end{itemize}
\end{definition}


\begin{definition}[Group-Induced Equivalence Partition]
  Let $G$ be an action group and $X$ be a set. The action of the group $G$ over $X$ induces an equivalence relation such that, for $x_1,x_2 \in X$:
  $$x_1 \sim x_2 \qquad \text{if} \qquad  \exists g\in G\text{ such that } gx_1=x_2 .$$
  This relation induce a quotient space on $X$ and, therefore, a partition, that could be seen as an element of the lattice of partitions of $X$. We will denote this partition as $P(X,G).$
\end{definition}

Note that the inverse property on groups and the two properties of group actions imply that the equivalence relation is, in fact, an equivalence relation. We note a simple result in order to make this concept more manageable.

\begin{proposition}
  Let $G$ be a group, $\{g_1,...,g_n\}\subset G$ be a set that generates $G$ and $X$ be a set. We have that:
  $$P(X,G) = \lor_{i\in 1,...,n} P(X,<g_i>) ,$$

  where $<g_i>$ is the cyclic group generated by $g_i$.
\end{proposition}

    
\begin{definition}[Permutation]
    Given a finite set of variables $X = \{x_1,...,x_n\}$, a \emph{permutation} of $X$ is any injective mapping $\alpha:X \to X$. Each permutation induces a homonym function on $\alpha: Form_X \to Form_X$  that replaces every variable by its image by $\alpha$. This homonym function can be seen as the action of $alpha$ over $Form_X$.
\end{definition}

      For example given $X = \{a,b,c\}$, and a injective mapping $\alpha:X\to X$ such that: 
  \begin{equation}
     \begin{split}
       \alpha(a) \to c,\\
       \alpha(b) \to b,\\
       \alpha(c) \to a.
     \end{split}
 \end{equation}

 We can see set of all permutations over a set $X$ such that $|X|=n$ along with composition is the \emph{permutation group} on $n$ elements, $P_n$.\\

 In algebra the permutations group (further on \emph{classic permutation group}) consists in the group of injective mappings of $\{1,...,n\}$ along with composition, studied in most group algebra courses. In fact, what we define as permutation group is the action group of the classic permutation group over the set of variables. 

\begin{definition}
  Let $X$ be an non-empty set of variables. Given $A\subset X$ a negation of $A$ is a mapping $\sigma_{A}:Lit(X) \to Lit(X)$ defined by:
  $$
\sigma_{A}(x_{i})=
\begin{cases}
  \neg l & if l \in A, \\
  l & \text{ otherwise}.
\end{cases}$$

Where $Lit(X)$ is the set of literals over $X$. Each negation induces a homonym function $\sigma_{A}:Form_{X}\to Form_{X}$.
\end{definition}
The same way with the group of permutation this is also a the action group of a elementary group of negations over integers. Nonetheless, as this group may be a little more exotic, we include a proof that  is, in fact, a group.

\begin{proposition}
  The set of negations over a set $X$ and composition is a group.
\end{proposition}
\begin{proof}\hfill 
  \begin{itemize}
    \item Closure: We can see that $\sigma_{A}\circ\sigma_{B} = \sigma_{(A\cup B)\backslash (A\cap B)}$.
    \item Associativity: Associativity is inherited from the general associativity of composition.
    \item Identity: We have an identity element $\sigma_{\emptyset}$.
    \item Inverse: For every $A\subset X$, $\sigma_{A}^2 = \sigma_{\emptyset}$.
  \end{itemize}
\end{proof}

We will denote the group of negations over $n$ variables as $N_n$.

\begin{proposition}[$NP_n$]
  The set of negations and permutations on $n$ variables  along with the composition is a group, denoted by $NP_n$. 
\end{proposition}
\begin{proof}
  Note that every element $x\in NP_n$ can be expressed as $\alpha\circ \sigma$ where $\alpha$ is a permutation and $\sigma$ is a negation. Also note that 
  \begin{itemize}
    \item Closure: $\alpha\circ \sigma_{A} \circ \alpha'\circ \sigma_{A'} = \alpha \circ \alpha' \circ \sigma_{\alpha^{-1} A} \circ \sigma_{A'}  = \alpha''\circ \sigma_{A''}$, where $\alpha''$ is a permutation and $\sigma_{A''}$ is a negation.
    \item Associativity: associativity is inherited from the general associativity of composition.
    \item Identity: we have an identity element $\sigma_{\emptyset}=I$.
    \item Inverse: for every $\alpha \circ \sigma_A$ the function $\alpha^{-1}\circ \sigma_{\alpha(A)}$ is its inverse.
  \end{itemize}
\end{proof}

\begin{proposition}
  $NP_n$ s the semi-direct product of $N_n$ and $P_n$. That is:
   $$NP_n = N_n \rtimes P_n.$$
 \end{proposition}
 
\begin{proof}
Note that due to the property aforementioned, $NP_n = P_nN_n$ and $P_n\cap N_n = I$. Therefore $NP_n$ is the semi direct product of $P_n$ and $N_n$.
\end{proof}

For us, a symmetry of a formula $F$ is any $\phi\in NP_{|Var(n)|}$ that is an invariant for $F$. We will have three type of symmetries:
\begin{itemize}
\item Value: a symmetry $\phi$ will be called a value symmetry if $\phi \in N_n$. The idea behind this name resides in the fact can flip the value of this variable without changing the truth value of the formula.
\item Variable: a symmetry $\phi$ will be called a variable symmetry if $\phi \in P_n$. The idea behind this name resides in the fact can swap two of this variables without changing the truth value of the formula.
\item Mixed: a symmetry that is not a value symmetry neither a variable symmetry is a mixed symmetry. The idea behind this name resides in the fact that this symmetries has to be a composition of a value symmetry with a variable symmetry.
\end{itemize}





We are going to search symmetries in a CNF formula $F$. Until now we have a naive method in order to do this: for every $\phi \in NP_n$ check whether $\phi$ is an invariant of $F$. Nonetheless the complexity of this process is as hard as solving SAT. Instead, we will in fact reduce the problem of symmetries detection to a colored graph  automorphism problem[\ref{sec:complexity}].\\








\begin{definition}
  Let $G = (V,E)$ be a graph where $V$ is the set of nodes and $E$ the set of edges, represented as unordered pairs. A \emph{coloring} of a graph its a partition  $(V_1,...,V_n)$ of $V$. Each  $V_i$ is called a \emph{color}, and for every $x\in V_i$ it is said that $x$ with color $i$. Also, let $v\in V$ we define $$d(v, V_i) = |\{u \in V_i : (u,v)\in E\}|.$$
  We say that a coloring is \emph{stable} if
  $$d(u,V_i) = d(v,V_i), \qquad  \forall u,v \in V_j,\ \forall i,j \in 1,...,n.$$

  A \emph{colored graph} is a pair $(G,\pi)$ where $G$ is a graph and $\pi$ is a coloring of it.
\end{definition}


We are going to associated our formula with a colored graph as defined above, and choose a coloring $pi$ of that graph. From every coloring $\pi$ of $G$ we can make a stable coloring $\pi'$ by iteratively splitting colors with different vertex degree. We can see that $\pi' \le_\mathcal{P} \pi$. If $\pi'$ is a discrete partition, i.e. $|\pi'| = |V|$,  $G$ has no symmetries beyond the identity. Otherwise we have some candidates for symmetry. This possible symmetry is checked (or refuted) by selecting a color $V_i\in \pi' = \{V_i : 1 \le i \le n\}$ with more than one element, and, for each $v\in V_i$ we put $v$ in front of $V_i \backslash \{v\}$, generating all symmetries.

\begin{example}

A little example of the procedure may be of some help:
\begin{figure}[H]
  \centering
  
  \begin{tikzpicture}[scale = 0.5,node distance=3cm,on grid,auto,thick] 
    % comentar para estilo básico
    \tikzstyle{every state}=[draw=myred!50,very thick,fill=myred!25,minimum size=1.2cm]
    \node[state] (q_0)   {$0$}; 
    \node[state] (q_1) [below=of q_0] {$1$}; 
    \node[state](q_2) [right=of q_1] {$2$};
    \node[state](q_3) [left=of q_1] {3};
    
    \path[->] 
    (q_1) edge node {} (q_0)
    (q_0) edge node {} (q_1)
    (q_1) edge node {} (q_2)
    (q_2) edge node {} (q_1)
    (q_3) edge node {} (q_1)
    (q_1) edge node {} (q_3)
    (q_2) edge node {} (q_0)
    (q_0) edge node {} (q_2);

    
  \end{tikzpicture}
  
  \caption{Initial Graph}
\end{figure}

 We now have a partition with only one set with all nodes. We will make a refinement by selecting the node with different adjacency. Now we have a new coloring.


\definecolor{mycolor}{RGB}{0, 128, 0}

\begin{figure}[H]
  \centering
  
  \begin{tikzpicture}[scale = 0.5,node distance=3cm,on grid,auto,thick] 
    % comentar para estilo básico
    \tikzstyle{every state}=[draw=myred!50,very thick,fill=myred!25,minimum size=1.2cm]
    \node[state] (q_0) [draw=blue!50,very thick,fill=blue!25]  {$0$}; 
    \node[state] (q_1) [below=of q_0] {$1$}; 
    \node[state](q_2) [right=of q_1, draw=blue!50,very thick,fill=blue!25] {2};
    \node[state](q_3) [draw=mycolor!50, fill=mycolor!25 , left=of q_1] {3};
    
    \path[->] 
    (q_1) edge node {} (q_0)
    (q_0) edge node {} (q_1)
    (q_1) edge node {} (q_2)
    (q_2) edge node {} (q_1)
    (q_3) edge node {} (q_1)
    (q_1) edge node {} (q_3)
    (q_2) edge node {} (q_0)
    (q_0) edge node {} (q_2);

    
  \end{tikzpicture}
  \caption{First modification.}
\end{figure}


Now we have an stable coloring, with a partition $\pi' = \{V_i: 1\le i\le 3\}$, where $V_1 = \{0,2\}$, $V_2 = \{1\}$ and $V_3 = \{3\}$. We represent this partition with a table:


\begin{table}[h]
  \begin{center}
    \begin{tabular}{|l|l|l|l|l|}
      \hline
      Node & 0 & 2 & 1 & 3 \\
      \hline
      Color & 1 & 1 & 2 & 3 \\
      \hline

    \end{tabular}
  \end{center}
  \caption{Coloring Table.}
\end{table}



In order to verify if this is a partition we put each one of the element in the front, change it color.

\begin{table}[h]
  \begin{center}
    \begin{tabular}{|l|l|l|l|l|}
      \hline
      Original & 0 & 2 & 1 & 3 \\
      \hline
      Modified 1 & 0 & 2 & 1 & 3 \\
      \hline
      Color Modified 1& 1'  & 1 & 2 & 3 \\
      \hline
      Modified 2 & 2 & 0 & 1 & 3 \\
      \hline
      Color Modified 2& 1'  & 1 & 2 & 3 \\
      \hline
    \end{tabular}
  \end{center}
  \caption{Partition Table.}
\end{table}

And now we reach, in both modification, a discrete coloring. Now we have two symmetries, each one induced by one modified coloring. We have all symmetries on the selected graph:
\begin{itemize}
\item The first coloring induces the trivial symmetry.
\item The second induces the symmetry of swapping 0 and 2.
\end{itemize}

\end{example}

Now that we have the right tool we can deepen in our study. In order to discover symmetries between in a formula $F$  we will apply this method to it associated symmetry graph $S_F$.

\begin{definition}
  Let $F$ be a CNF formula, the associated symmetry graph $S_F$, is a colored undirected graph such that:
  \begin{itemize}
  \item has as nodes:
    \begin{itemize}
    \item Clause node: there is a node $n_C$ with color 0 for every clause $C \in F$.
    \item Positive Literal node: there is a node $n_x$ with color 1 for every variable $x\in Var(F)$.
    \item Negative Literal node: there is a node $n_{\neg x}$ with color 1 every variable $x\in Var(F)$.
    \end{itemize}
  \item has as edges (represented as unordered pairs):
    \begin{itemize}
    \item Clause edges: for every clause $C\in F$, and for every literal $l\in C$ there is an edge $(n_c, n_l)$.
    \item Variable edges: for every variable $x\in Var(F)$ there is an edge $(n_x,n_{\neg x})$.
    \end{itemize}
  \end{itemize}
\end{definition}





Once we have detected for our formula $F$  its group of symmetries $\mathfrak{G}_F$ we want to disambiguate it properties. That is, in the same fashion as Clause Learning \ref{sub:clauselearning}, we want to add a predicate in order to allow any algorithm to consider the rest of the values possible automatically.\\

Although this idea tend to be portrayed with a lot of fancy tools, it is in fact really simple idea once well explained: we are going to order the satisfying assignments of $F$ and only consider true the least of them. This idea is correct, as we can easily make a ordering on the assignment of $Var(F)$. The interesting idea of this method resides on how to translate it to propositional logic language.\\

We are going to order the assignments in  lexicographic order. We are going to consider that $Var(F) = \{x_i : 1 \le i \le n\}$, and being $\alpha, \beta$ two assignments on $Var(F)$ then
\begin{align*} 
  \alpha \le \beta \iff& \exists i \in 1,...,n \text{ such that }\\  &(\alpha(x_i+1) = \beta(x_i+1):\forall j \in 1,...,n  ) \implies\alpha( x_i) \le\beta (x_i).
\end{align*}
    
Then we are going to impose that, for every orbit of a symmetry $\pi \in \mathfrak{G}_F$, we have that $\alpha\le \alpha\circ\pi$, therefore having only one correct assignment. This is translated to formulas achieved thanks to lex-leader predicate.


\begin{definition}[10.7\cite{sakallah2009symmetry}]

  Let $F$ be a CNF formula, $X=\{x_i: 1\le i \le n\}=Var(F)$ and $\pi \in \mathfrak{G}_F$, we define the \emph{lex-leader predicate} $PP(X,\pi)$ as

  $$PP(X,\pi) = \land_{1\le i \le n} \left (\left (
    \land_{i+1 \le j \le n} (x_j = \pi(x_j)) \right )  \to (x_i \le \pi(x_i) )\right ).$$
\end{definition}


\begin{definition}

  Let $F$ be a CNF formula, and $\mathfrak{G}_F$ be its symmetry group. We define the \emph{symmetry breaking predicate} $\rho(F)$ as:

  $$ \rho(F)  = \land_{\pi \in \mathfrak{G}_F} PP(X,\pi).$$

\end{definition}


And we have that, considering $F\land \rho(F)$ only the least of the symmetries can be considered. 





 
\subsection{Autarks assignments}
\label{sec:autark}

Once we have defined what is a CNF formula and what is a problem we can proceed to define this anticipated concept.

\begin{definition}
  An partial assignment $\alpha$ is called autark for a CNF formula $F$ if for every clause $C \in F$ it happens that if $Var(C) \cap Var(\alpha) \ne \emptyset $ then $C\alpha = 1$.
\end{definition}

An autark assignment $\alpha$  for a CNF formula $F$ is an assignment that satisfies all clauses that it 'touches'. These assignments provide simplifications of the CNF formulas in the context of satisfiability, as they generate a new CNF formula $F\alpha$ that are satisfiable if, and only if,  $F$ is satisfiable. In set notation we can state that $\alpha$ is autark for $F$ if $F\alpha \subsetneq F$. Subsequently, trying to find simple autark assignment, is a good praxis.\\


Should it happen that we have an algorithm for the Autarks Finding Problem, iterating it, we could find a satisfying assignment of any given formula if it exists such assignment, therefore solving FSAT.  Let's define the problem formally:

\begin{definition}
  Let $CNF$ the set of formulas in CNF and $Part$ the set of partial assignments. The Autark Finding Problem is the function problem defined by the relation:\\

\begin{equation}
\begin{split}
    R\ =\ \{(F,\alpha)\ :\ & F \in CNF\wedge \forall C \in F,\\ & C\ne \emptyset\ \ ( Var(C)\cap Var(\alpha)\ne\emptyset \implies C\alpha=1 )\}.
\end{split}
\end{equation}
  
\end{definition}

\begin{theorem}\label{the:autark}
  There is a reduction from FSAT to the Autark-Finding problem.
\end{theorem}
\begin{proof} Suppose that an algorithm such that if it exists any autark it return one of them, and end with an error code otherwise is given.  \\

    Given a formula $F$, if there is not an autark then there is no solution for the SAT problem. If it finds an Autark-assignment $\alpha$ then we apply the same algorithm to $\alpha(F)$. Also, as it happens that $|Var(\alpha(F))|<|Var(F)|$ so we only apply the algorithm finitely many times. Also, $F$ will be solvable if, and only if, $F\alpha$ is solvable.
\end{proof}


The most common autark assignment is the pure literal. A literal $l$ is a pure literal for a formula $F$ if there is no $\neg l$ in $F$. The partial-assignment that only maps $u\to 1$ is an autark assignment for $F$. This type of autark are used on DPLL algorithm[\ref{sec:dpll}]. The MS algorithm[\ref{alg:MS}] also uses an autark finding technique.

\begin{corollary}
The autark finding problem is FNP-Complete.
\end{corollary}

\begin{proof}
As checking whether an assignment is autark is linear on the number of clauses, then this make the autark-finding problem is in FNP. From \ref{the:autark} follows that the autark finding problem is FNP-Complete.
\end{proof}
 


\subsection{Tseitin Theorem}
TODO: Redo the operations
Now that we are able to talk about efficiency is time to talk about an interesting, anticipated result. If we remember Lindenbaum algebra[\ref{def:linden}] we have defined a quotient space on the formulas in terms of satisfiability. In order to solve GSAT, we are not in need of solving all formulas.  Instead we can learn how to solve a language of formulas $\mathsrc{F}$ such that for every class $[\phi_1]\in Form/\sim$ there  is a formula $f\in\mathsrc{F}$ such that $f \in [\phi_1]$. Also, we will need a method that allows us to find such $f\in\mathsrc{F}$ given any element of $[\phi_1]$.We want to prove that SAT is a language that satisfies this restrictions. The naive approach to the problem is straightforward:\\

\begin{proposition}
  There is a $CNF$ formula in each equivalence class. Moreover, given a function $f\in Form$ we are able to find an equivalent $CNF$ formula.
\end{proposition}
\begin{proof}
 Given $\phi_1 \in Form$ we make the truth table of $\phi_1$. Two formulas are in the same equivalent classes if, and only if, they share the same truth table. \\

  We can generate a $CNF$ formula that has the same table this way: for every row $[x_1\to a_1,...,x_n\to a_n]$ ($x_i$ variables, $a_i\in \{0,1\}$) that falsifies $\phi_1$ we add a clause $(z_1\vee ... \vee z_n)$ with $z_i = x_i$ if $a_i = 0$ and  $z_i =\neg x_i$ if $a_i = 1$.
\end{proof}


  This method is interesting as it shows the truth table, as the collection of all two-valued assignments$\alpha$ such that $Var(\alpha) = \phi_1$. Nonetheless is not a method that should be considered useful, as it has exponential time. Tseitin theorem provides us with a solution to this problem that runs in polynomial time. We will need a lemma first:

  \begin{lemma}
    For every \emph{SAT} formula there is an associated circuit.
  \end{lemma}
  \begin{proof}
    Every operator can be seen as a gate and every variable as an input.\\
  \end{proof}
  
  \begin{theorem}[Tseitin \cite{tseitin1983complexity}] \label{the:Tseitin}
    There is a 3-CNF formula on each equivalent class. Moreover, given an element $F$  there is a equivalent formula $G$  in 3-CNF which could be computed in polynomial time. 
  \end{theorem}

  \begin{proof}
    We will show that for every circuit with $n$ inputs and $m$ binary gates there is a formula in \emph{3-CNF}  that could be constructed in polynomial time in $n$ and $m$. Then, given a formula we will work with it considering its associated circuit.\\
    
    We will construct the formula considering variables $x_1,...,x_n$ that will represent the inputs and $y_1,...,y_m$ that will represents the output of each gate. 

    $$ G = (y_1) \wedge \bigwedge_{i=1}^m (y_i \iff f_i(z_{i,1},z_{i,2})).$$

    Where $f_i$ represents the formula associated to the $i$-gate, $z_{i,1},z_{i,2}$ each of the two inputs of the $i$-gate, whether they are $x_-$ or $y_-$ variables. This formula is not \emph{3-CNF} yet, but for each configuration being $f_i$ a Boolean operator there would be a \emph{3-CNF} equivalent.

    \begin{itemize}
    \item $z \iff( x \vee y )= ( x \lor y \lor \neg z) \land (\neg x \lor z) \land (\neg y \lor z).$
    \item $z\iff( x \wedge y ) =   (\neg  x \vee z) \wedge (\neg  y \vee z ) \wedge (\neg  z \vee x ) \wedge (\neg  y \vee x ) \wedge(\neg  z\vee y )\wedge (\neg  x\vee y ).$
      
    \item $
z\! \iff\!( x\! \iff\! y )\! =\! (x\! \lor\!  \neg y \lor\! z) \land\! (\neg x\! \lor\! y\! \lor\! \neg z) \!\land\! (x\! \lor\! \neg y\! \lor\! \neg z)\! \land\! (x \lor y \lor z).$



      
    \item $z \iff( x \oplus y ) =  z \iff(\neg  x \iff y ) . $	

    \end{itemize}
    In the last item we use the third one.
    
  \end{proof}

  The fact that they are reachable on polynomial time is important because it means it could be done efficiently. Should this be impossible it will not be of much relevance in practice, as we yearn to solve this problem as efficiently as possible. This result implies that if we know how to solve $3$-SAT we know how to solve GSAT.


  \subsection{Tautologies Revisited}

  \begin{proposition}
    Given a tautology $F \to G$, there exists a formula $I$ such that $Var(I) = Var(F)\cap Var(G)$ and both $F\to I$ and $I \to G$ are tautologies. A polynomial algorithm to solve this problem is not known. 
  \end{proposition}

  \begin{proof} Let $\{x_1,...,x_k\} = Var(F)\cup Var(G)$ then we will build $I$ by defining its truth table in the following way: Given an assignment $\alpha$:
    \[   
      I\alpha = 
      \begin{cases}
        1&\quad\text{if $\alpha$ could be extended to an assignment that \emph{satisfies} $F$}, \\
        0&\quad\text{if $\alpha$ could be extended to an assignment that \emph{nullifies} $G$},\\
        * &\quad\text{otherwise.} \\ 
      \end{cases}
    \]

    Where * mean that it could be either 0 or 1.  This is well defined because if for an arbitrary $\alpha$ it happens that $G\alpha = 0$ then $F\alpha = 0$.

    For every assignment $\beta$ such that $Var(\beta) = Var(F)\cup Var(G)$ then if $\beta(F) = 1$ then $\beta(I) = 1$ so $F \to I$  is a tautology. Similarly it can not happen that $I\beta = 1 $ and $G\beta = 0$, because the second will imply that   $I\beta = 0$.\\

    For the last part we will refer to \cite{schoning2007note}.
  \end{proof}

  
  \subsection{From non-constructive to constructive}
  \label{sub:fromnon}
  In this subsection we explain how a constructive SAT-solver can be made from a non-constructive SAT-solver without changing its asymptotic time complexity, assuming true the exponential time hypothesis[\ref{hyp:exponential_time}]. 

  \begin{proposition}
    Let $\phi$ be an oracle that decides SAT in $O(\varphi(n+m))$ where $n$ is the number of variables and $m$ the number of clauses. Then we can make an algorithm  that computes FSAT on $O((n(\varphi(n+m))+m)$ 
  \end{proposition}
  \begin{proof}
    We will iteratively expand a partial assignment $\alpha$. $\alpha$ initially maps all variables to $\upsilon$. The procedure take as input a CNF formula $F$. The algorithm that solve FSAT is described in [\ref{alg:constructive}]. It is based in the notion that, if  $F$ is satisfiable, either $F\{x=1\}$ or $F\{x=0\}$ is satisfiable. We are able to explore the variable lineally being sure that we are always assigning the correct value to each variable. 

    
    \begin{algorithm}
  \caption{FSAT routine}\label{alg:constructive}
  \begin{algorithmic}[1]

    
  \Procedure{Solver}{$F$}
  \State $F_0 \gets F$
  \State $\alpha \gets$ empty partial assignment.
  \State
    \For{$x\in Var(F)$}
    \If{$\phi(F_0\{x=1\})$}
    \State $\alpha += \{x = 1\}$
    \State $F_0 \gets F_0\{x=1\}$
    \Else \If{$\phi(F_0\{x=0\})$} 
    \State $\alpha += \{x = 0\}$
    \State $F_0 \gets F_0\{x=0\}$
    \Else
    \State \Return Unsatisfiable
    \EndIf
    \EndIf
    \EndFor
    \State \Return $\alpha$
  \end{algorithmic}
\end{algorithm}

Let's analyze the complexity of this algorithm. We make at most $n$ repetitions of the for loop, and on each repetition we call $\phi$ and assign a variable in a formula.Therefore the procedure runs in $O(n\varphi(n+m)+m)$
\end{proof}

Assuming ETH we assume that $\phi$ is exponential in time, an therefore asymptotic complexity $O(\varphi(n+m))$ is the same as $O(n(\varphi(n+m)+m))$, so, until $ETH$ is proved wrong we can consider SAT and FSAT as being equal in complexity. On this text we will only deal with non-constructive  solvers on the combinatorics section[\ref{sec:combu}]. 
